{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "###**Criar um classificador de sentimento aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "Utilizando o dataset de revisões de filmes em português [1], criar um classificador de sentimentos que consiga um score na métrica F1 Score superior a 70%.\n",
        "\n",
        "Devem utilizar uma amostra de 20% e randon_state igual a 42 para testar as implementações e mensurar a métrica F1 Score (usar o parâmetro average = 'weighted') o restante dos dados devem ser utilizados para o treinamento (80%).\n",
        "\n",
        "Fique a vontade para testar os métodos de pré-processamento, abordagens, algoritmos e bibliotecas, mas explique e justifique suas decisões.\n",
        "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
        "\n",
        "Separe a implementação do seu modelo campeão junto com a parte de validação/teste de forma que o professor consiga executar todo o pipeline do modelo campeão.\n",
        "\n",
        "Composição da nota:\n",
        "- 50% - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, etc.)\n",
        "- 50% - Baseado na performance obtida com o dataset de teste (conforme recomendação da amostra) no seu modelo campeão e na validação que o professor processar (Métrica F1 Score)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzhQpodBpRpX"
      },
      "source": [
        "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKC9Vhkp0BK"
      },
      "source": [
        "Bom desenvolvimento!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy #!pip install spacy\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv', encoding='utf-8')\n",
        "\n",
        "# Façam o download do arquivo e utilizem localmente durante os testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44514 entries, 0 to 44513\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   codigo      44514 non-null  int64 \n",
            " 1   texto       44514 non-null  object\n",
            " 2   sentimento  44514 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "25cBRwGAw8-1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/njaneto/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carrega StopWords\n",
        "nlp = spacy.load('pt_core_news_sm') #python3 -m spacy download pt_core_news_sm\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# stopwords NLTK\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# stopwords SpaCy\n",
        "stops_spacy = nlp.Defaults.stop_words\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
        "len(stops)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# função de lematização completa do documento\n",
        "def fn_lematiza_texto(texto):\n",
        "    sent = []\n",
        "    doc = nlp(texto)\n",
        "    for word in doc:\n",
        "        sent.append(word.lemma_)\n",
        "        \n",
        "    return ' '.join(sent)\n",
        "\n",
        "# função de lematização dos verbos do documento\n",
        "def fn_lematiza_verb_texto(texto):\n",
        "    sent = []\n",
        "    doc = nlp(texto)\n",
        "    for word in doc:\n",
        "        if word.pos_ =='VERB':\n",
        "            sent.append(word.lemma_)\n",
        "        else:\n",
        "            sent.append(word.text)\n",
        "    return \" \".join(sent)\n",
        "\n",
        "\n",
        "# função para limpar documento\n",
        "def fn_limpa_texto(texto):\n",
        "    texto = re.sub(r'@\\w+','',texto)\n",
        "    texto = re.sub(r'#','',texto)\n",
        "    texto = re.sub(r'RT[\\s]+','',texto)  \n",
        "    #texto = re.sub(r'rt[\\s]+','',texto)  \n",
        "    texto = re.sub(r'https:/\\/\\S+','',texto)\n",
        "    texto = re.sub(r'[,.:;]','',texto)\n",
        "    texto = re.sub(r'\\n',' ',texto)\n",
        "    texto = re.sub(u'[^a-zA-ZâêîôûÂÊÎÔÛáéíóúÁÉÍÓÚàèìòùÀÈÌÒÙãõÃÕçÇ ]', '', texto)\n",
        "    texto = texto.strip().lower()\n",
        "    \n",
        "    return texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aplica normalização no dataframe\n",
        "df['texto_trat'] = df.texto.apply(fn_lematiza_texto)\n",
        "\n",
        "# aplica a lematização no dataframe\n",
        "df['texto_lemma'] = df.texto_trat.apply(fn_lematiza_texto)\n",
        "\n",
        "# aplica a lematização dos verbos no dataframe\n",
        "df['texto_lemma_verb'] = df.texto_trat.apply(fn_lematiza_verb_texto)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# analisa alguns dados\n",
        "print(df['texto'][1])\n",
        "print(df['texto_trat'][1])\n",
        "print(df['texto_lemma'][1])\n",
        "print(df['texto_lemma_verb'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pré-processamento vetorização e BOW\n",
        "# Frequência de termos - term frequency–inverse document frequency (TF-IDF)\n",
        "vetor = TfidfVectorizer(ngram_range=(1,2), use_idf=True) #0.7729036810537457 - TF-IDF, texto lematixado, uni e bi brama, Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# texto tratado\n",
        "vetor.fit(df.texto_trat)\n",
        "text_vect = vetor.transform(df.texto_trat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# texto tratado e lematizado\n",
        "vetor.fit(df.texto_lemma)\n",
        "text_vect = vetor.transform(df.texto_lemma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# texto tratado e verbos lematizado\n",
        "vetor.fit(df.texto_lemma_verb)\n",
        "text_vect = vetor.transform(df.texto_lemma_verb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# separa as amostras de Treino (80%) e Texte (20%)\n",
        "X_train,X_test,y_train,y_test = train_test_split( text_vect,  df['sentimento'], test_size = 0.2, random_state = 42 )\n",
        "\n",
        "# define e treina o modelo de classificação\n",
        "#modelo = LogisticRegression(random_state=42)\n",
        "#modelo = DecisionTreeClassifier(random_state=42)\n",
        "modelo = MultinomialNB()\n",
        "\n",
        "#modelo = LogisticRegression(penalty = 'l2', C = 100, random_state=42)\n",
        "\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# valida a parformance\n",
        "y_prediction = modelo.predict(X_test)\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "####**Validação do professor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24EasckqG2I"
      },
      "source": [
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxqHA-XCrqsD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFA-CYfawkEJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuJtvcfXo3J4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ULYNH6-o3Hf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ClM-JTJo3FK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TemplateTrabalhoFinal-NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
