{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDbi6PDS9MYO"
   },
   "source": [
    "***Participantes (RM - NOME):***<br>\n",
    "xxxx - xxxxx<br>\n",
    "xxxx - xxxxx<br>\n",
    "xxxx - xxxxx<br>\n",
    "xxxx - xxxxx<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xw6WhaNo4k3"
   },
   "source": [
    "###**Criar um classificador de sentimento aplicando técnicas de PLN**\n",
    "---\n",
    "\n",
    "Utilizando o dataset de revisões de filmes em português [1], criar um classificador de sentimentos que consiga um score na métrica F1 Score superior a 70%.\n",
    "\n",
    "Devem utilizar uma amostra de 20% e randon_state igual a 42 para testar as implementações e mensurar a métrica F1 Score (usar o parâmetro average = 'weighted') o restante dos dados devem ser utilizados para o treinamento (80%).\n",
    "\n",
    "Fique a vontade para testar os métodos de pré-processamento, abordagens, algoritmos e bibliotecas, mas explique e justifique suas decisões.\n",
    "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
    "\n",
    "Separe a implementação do seu modelo campeão junto com a parte de validação/teste de forma que o professor consiga executar todo o pipeline do modelo campeão.\n",
    "\n",
    "Composição da nota:\n",
    "- 50% - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, etc.)\n",
    "- 50% - Baseado na performance obtida com o dataset de teste (conforme recomendação da amostra) no seu modelo campeão e na validação que o professor processar (Métrica F1 Score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzhQpodBpRpX"
   },
   "source": [
    "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyKC9Vhkp0BK"
   },
   "source": [
    "Bom desenvolvimento!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nze8UbKhosm9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31590/1606087491.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import spacy #!pip install spacy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ue0nV0uVo3OZ"
   },
   "outputs": [],
   "source": [
    "# CARREGANDO O DATA FRAME\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/reviews-pt-br.csv', encoding='utf-8')\n",
    "\n",
    "# Façam o download do arquivo e utilizem localmente durante os testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FziwgqJmw9OD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44514 entries, 0 to 44513\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   codigo      44514 non-null  int64 \n",
      " 1   texto       44514 non-null  object\n",
      " 2   sentimento  44514 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "25cBRwGAw8-1"
   },
   "outputs": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31590/1606087491.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
            "  from tqdm._tqdm_notebook import tqdm_notebook\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pickle\n",
        "import spacy #!pip install spacy\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv', encoding='utf-8')\n",
        "\n",
        "# Façam o download do arquivo e utilizem localmente durante os testes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega StopWords\n",
    "nlp = spacy.load('pt_core_news_sm') #python3 -m spacy download pt_core_news_sm\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# stopwords NLTK\n",
    "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "# stopwords SpaCy\n",
    "stops_spacy = nlp.Defaults.stop_words\n",
    "\n",
    "# stopwords do SpaCy e NLTK combinadas\n",
    "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
    "len(stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de lematização dos verbos do documento\n",
    "def fn_lematiza_verb_texto(texto):\n",
    "    sent = []\n",
    "    doc = nlp(texto)\n",
    "    for word in doc:\n",
    "        if word.pos_ =='VERB':\n",
    "            sent.append(word.lemma_)\n",
    "        else:\n",
    "            sent.append(word.text)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "# função para limpar documento\n",
    "def fn_limpa_texto(texto):\n",
    "    result = []\n",
    "    texto = re.findall(r\"[a-zA-z]+\", texto)\n",
    "    for w in texto:\n",
    "        w = w.lower()\n",
    "        if w in stops:\n",
    "            continue\n",
    "        result.append(w)\n",
    "        \n",
    "    texto = ' '.join(result)\n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "text/plain": [
       "  0%|          | 0/44514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "25cBRwGAw8-1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/njaneto/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carrega StopWords\n",
        "nlp = spacy.load('pt_core_news_sm') #python3 -m spacy download pt_core_news_sm\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# stopwords NLTK\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# stopwords SpaCy\n",
        "stops_spacy = nlp.Defaults.stop_words\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
        "len(stops)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# função de lematização dos verbos do documento\n",
        "def fn_lematiza_verb_texto(texto):\n",
        "    sent = []\n",
        "    doc = nlp(texto)\n",
        "    for word in doc:\n",
        "        if word.pos_ =='VERB':\n",
        "            sent.append(word.lemma_)\n",
        "        else:\n",
        "            sent.append(word.text)\n",
        "    return \" \".join(sent)\n",
        "\n",
        "def fn_limpa_texto(texto):\n",
        "    texto = re.sub(r'@\\w+','',texto)\n",
        "    texto = re.sub(r'#','',texto)\n",
        "    texto = re.sub(r'RT[\\s]+','',texto)  \n",
        "    #texto = re.sub(r'rt[\\s]+','',texto)  \n",
        "    texto = re.sub(r'https:/\\/\\S+','',texto)\n",
        "    texto = re.sub(r'[,.:;]','',texto)\n",
        "    texto = re.sub(r'\\n',' ',texto)\n",
        "    texto = re.sub(u'[^a-zA-ZâêîôûÂÊÎÔÛáéíóúÁÉÍÓÚàèìòùÀÈÌÒÙãõÃÕçÇ ]', '', texto)\n",
        "    texto = texto.strip().lower()\n",
        "    \n",
        "    return texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83c2e47e54c64649a9dabb8450c3a37a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/44514 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11bb663174674d99990c49d30f4b0bbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/44514 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# aplica a lematização no dataframe\n",
        "df['texto_trat'] = df.texto.progress_apply(fn_limpa_texto)\n",
        "# aplica a lematização no dataframe\n",
        "df['texto_lemma_verb'] = df.texto_trat.progress_apply(fn_lematiza_verb_texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pré-processamento vetorização e BOW\n",
        "# Frequência de termos - term frequency–inverse document frequency (TF-IDF)\n",
        "vetor = TfidfVectorizer(ngram_range=(1,2), use_idf=True) #0.7729036810537457 - TF-IDF, texto lematixado, uni e bi brama, Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# texto tratado e verbos lematizado\n",
        "vetor.fit(df.texto_lemma_verb)\n",
        "text_vect = vetor.transform(df.texto_lemma_verb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2226, 215295)\n",
            "0.7399103139013453\n"
          ]
        }
      ],
      "source": [
        "# separa as amostras de Treino (80%) e Texte (20%)\n",
        "X_train,X_test,y_train,y_test = train_test_split( text_vect,  df['sentimento'], test_size = 0.2,random_state = 4 2)\n",
        "\n",
        "# define e treina o modelo de classificação\n",
        "#modelo = LogisticRegression(random_state=42)\n",
        "#modelo = DecisionTreeClassifier(random_state=42)\n",
        "modelo = MultinomialNB()\n",
        "\n",
        "#modelo = LogisticRegression(penalty = 'l2', C = 100, random_state=42)\n",
        "\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# valida a parformance\n",
        "y_prediction = modelo.predict(X_test)\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pickle.dump(vetor, open('modelo_verorizacao.pkl', 'wb'))\n",
        "pickle.dump(modelo, open('modelo_classificacao.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "####**Validação do professor**"
      ]
    },
    {
     "data": {
      "text/plain": [
       "neg    22307\n",
       "pos    22207\n",
       "Name: sentimento, dtype: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxqHA-XCrqsD"
      },
      "outputs": [],
      "source": [
        "novo_vetor = pickle.load(open('modelo_verorizacao.pkl', 'rb'))\n",
        "novo_modelo = pickle.load(open('modelo_classificacao.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFA-CYfawkEJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "neg    22307\n",
              "pos    22207\n",
              "Name: sentimento, dtype: int64"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfValida = df.sample(frac=0.50)\n",
        "dfValida.info()\n",
        "dfValida.sentimento.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ULYNH6-o3Hf"
      },
      "outputs": [],
      "source": [
        "dfValida['texto_trat'] = dfValida.texto.apply(fn_limpa_texto)\n",
        "\n",
        "# aplica a lematização no dataframe\n",
        "dfValida['texto_lemma_verb'] = dfValida.texto_trat.apply(fn_lematiza_verb_texto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ClM-JTJo3FK"
      },
      "outputs": [],
      "source": [
        "text_vect = novo_vetor.transform(dfValida.texto_lemma_verb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predito = novo_modelo.predict(text_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# valida a parformance\n",
        "accuracy = accuracy_score(predito, dfValida.sentimento)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TemplateTrabalhoFinal-NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
   ],
   "source": [
    "dfValida = df.sample(frac=0.50)\n",
    "dfValida.info()\n",
    "dfValida.sentimento.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ULYNH6-o3Hf"
   },
   "outputs": [],
   "source": [
    "dfValida['texto_trat'] = dfValida.texto.apply(fn_limpa_texto)\n",
    "\n",
    "# aplica a lematização no dataframe\n",
    "dfValida['texto_lemma_verb'] = dfValida.texto_trat.apply(fn_lematiza_verb_texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ClM-JTJo3FK"
   },
   "outputs": [],
   "source": [
    "text_vect = novo_vetor.transform(dfValida.texto_lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predito = novo_modelo.predict(text_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valida a parformance\n",
    "accuracy = f1_score(predito, dfValida.sentimento, average='weighted')\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TemplateTrabalhoFinal-NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
